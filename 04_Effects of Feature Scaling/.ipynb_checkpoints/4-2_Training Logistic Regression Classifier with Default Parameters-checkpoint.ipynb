{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Logistic Regression\n",
    "\n",
    "- Logistic Regression is a simple, linear classifier. Due to its simplicity. It is often a good first classifier to try.\n",
    "\n",
    "\n",
    "- It takes a weighted combbination of the input features, and passes it through a sigmoid function, which smoothly maps any real number to a number between 0 and 1. The functions transforms a real number input, x, into a number betwen 0 and 1.\n",
    "\n",
    "\n",
    "> A logistic classifier would predict the positive class if the sigmoid output is greater than 0.5,and the negative class otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Yelp business data \n",
    "\n",
    "biz_f = open('../../data/yelp_dataset/yelp_academic_dataset_business.json', encoding='utf8')\n",
    "biz_df = pd.DataFrame([json.loads(x) for x in biz_f.readlines()])\n",
    "biz_f.close()\n",
    "\n",
    "# Load Yelp Reviews data - 1,000,000 reviews\n",
    "f = open('../../data/yelp_dataset/yelp_academic_dataset_review.json', encoding='utf8')\n",
    "js = []\n",
    "for i in range(1000000):\n",
    "    js.append(json.loads(f.readline()))\n",
    "f.close()\n",
    "\n",
    "review_df = pd.DataFrame(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45704, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull-out only the Nightlife and Restaurant Businesses\n",
    "\n",
    "two_biz = biz_df[(biz_df.categories.str.contains('Restaurants')) | (biz_df.categories.str.contains('Nightlife'))]\n",
    "two_biz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with the reviews to get all reviews on the two types of business category\n",
    "\n",
    "twobiz_reviews = two_biz.merge(review_df, on='business_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim away the features we won't use\n",
    "twobiz_reviews = twobiz_reviews[['business_id',\n",
    "                                'name',\n",
    "                                'stars_y',\n",
    "                                'text', \n",
    "                                 'categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target column -- True for Nightlife businesses, and False otherwise\n",
    "\n",
    "twobiz_reviews['target'] = twobiz_reviews.categories.str.contains('Nightlife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class-balanced  classification dataset\n",
    "\n",
    "nightlife = twobiz_reviews[(twobiz_reviews.categories.str.contains('Nightlife'))]\n",
    "resto = twobiz_reviews[(twobiz_reviews.categories.str.contains('Restaurants'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Balance the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nytlife_subset = nightlife.sample(frac=0.1, random_state=123)\n",
    "resto_subset = resto.sample(frac=0.0268, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29432, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine = pd.concat([nytlife_subset, resto_subset])\n",
    "combine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test datasets\n",
    "\n",
    "training_data, test_data = model.train_test_split(combine, train_size=0.7, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Transform Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent the review text as a bag-of-words\n",
    "# We use CountVectorizer to convert the bag of words\n",
    "\n",
    "bow_transform = text.CountVectorizer()\n",
    "X_tr_bow = bow_transform.fit_transform(training_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_bow = bow_transform.transform(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = training_data['target']\n",
    "y_te = test_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tf-idf representation using the bag-of-words matrix\n",
    "\n",
    "tfidf_trfm = text.TfidfTransformer(norm=None)\n",
    "X_tr_tfidf = tfidf_trfm.fit_transform(X_tr_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_tfidf = tfidf_trfm.transform(X_te_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for kicks, l2-normalize the bag-of-words representation\n",
    "\n",
    "X_tr_l2 = preproc.normalize(X_tr_bow, axis=0)\n",
    "X_te_l2 = preproc.normalize(X_te_bow, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### Now Lets build some simple Logistic Regression Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description, _C=1.0):\n",
    "    ## Helper function to train a logistic classifier and score on test data\n",
    "    m = LogisticRegression(C=_C).fit(X_tr, y_tr)\n",
    "    s = m.score(X_test, y_test)\n",
    "    print('Test score with', description, 'features:', s)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score with bow features: 0.7221970554926387\n",
      "Test score with l2-normalized features: 0.7069082672706681\n",
      "Test score with tf-idf features: 0.6768969422423556\n"
     ]
    }
   ],
   "source": [
    "m1 = simple_logistic_classify(X_tr_bow, y_tr, X_te_bow, y_te, 'bow')\n",
    "m2 = simple_logistic_classify(X_tr_l2, y_tr, X_te_l2, y_te, 'l2-normalized')\n",
    "m3 = simple_logistic_classify(X_tr_tfidf, y_tr, X_te_tfidf, y_te, 'tf-idf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Paradoxically, the results sow that the most accurate classifier is the one using BoW features.\n",
    "\n",
    "> The reason is that the classifier are not well-tuned which is a common pitfall when comparing classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
