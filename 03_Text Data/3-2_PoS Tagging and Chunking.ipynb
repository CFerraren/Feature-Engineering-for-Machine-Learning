{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustrate Python Libraries to make chunking using PoS tagging.\n",
    "\n",
    "- spaCy \n",
    "\n",
    "- TextBlob\n",
    "---\n",
    "\n",
    "> Each Library are a little-bit different. Spacy includes common words in the English language like 'a' and 'the while TextBlob removes these.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Yelp Dataset Challenge\n",
    "\n",
    "- https://www.yelp.com/dataset/challenge\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first 10,000 reviews\n",
    "\n",
    "f = open('../../data/yelp_dataset/yelp_academic_dataset_review.json', encoding='utf8')\n",
    "js = []\n",
    "for i in range(10):\n",
    "    js.append(json.loads(f.readline()))\n",
    "f.close()\n",
    "\n",
    "review_df = pd.DataFrame(js)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we'll walk through spaCy's functions\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \u001b[93mInfo about model en\u001b[0m\n",
      "\n",
      "    lang               en             \n",
      "    pipeline           ['tagger', 'parser', 'ner']\n",
      "    accuracy           {'token_acc': 99.8698372794, 'ents_p': 84.9664503965, 'ents_r': 85.6312524451, 'uas': 91.7237657538, 'tags_acc': 97.0403350292, 'ents_f': 85.2975560875, 'las': 89.800872413}\n",
      "    name               core_web_sm    \n",
      "    license            CC BY-SA 3.0   \n",
      "    author             Explosion AI   \n",
      "    url                https://explosion.ai\n",
      "    vectors            {'keys': 0, 'width': 0, 'vectors': 0}\n",
      "    sources            ['OntoNotes 5', 'Common Crawl']\n",
      "    version            2.0.0          \n",
      "    spacy_version      >=2.0.0a18     \n",
      "    parent_package     spacy          \n",
      "    speed              {'gpu': None, 'nwords': 291344, 'cpu': 5122.3040471407}\n",
      "    email              contact@explosion.ai\n",
      "    description        English multi-task CNN trained on OntoNotes, with GloVe vectors trained on Common Crawl. Assigns word vectors, context-specific token vectors, POS tags, dependency parse and named entities.\n",
      "    link               /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
      "    source             /usr/local/lib/python3.6/dist-packages/en_core_web_sm\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lang': 'en',\n",
       " 'pipeline': ['tagger', 'parser', 'ner'],\n",
       " 'accuracy': {'token_acc': 99.8698372794,\n",
       "  'ents_p': 84.9664503965,\n",
       "  'ents_r': 85.6312524451,\n",
       "  'uas': 91.7237657538,\n",
       "  'tags_acc': 97.0403350292,\n",
       "  'ents_f': 85.2975560875,\n",
       "  'las': 89.800872413},\n",
       " 'name': 'core_web_sm',\n",
       " 'license': 'CC BY-SA 3.0',\n",
       " 'author': 'Explosion AI',\n",
       " 'url': 'https://explosion.ai',\n",
       " 'vectors': {'keys': 0, 'width': 0, 'vectors': 0},\n",
       " 'sources': ['OntoNotes 5', 'Common Crawl'],\n",
       " 'version': '2.0.0',\n",
       " 'spacy_version': '>=2.0.0a18',\n",
       " 'parent_package': 'spacy',\n",
       " 'speed': {'gpu': None, 'nwords': 291344, 'cpu': 5122.3040471407},\n",
       " 'email': 'contact@explosion.ai',\n",
       " 'description': 'English multi-task CNN trained on OntoNotes, with GloVe vectors trained on Common Crawl. Assigns word vectors, context-specific token vectors, POS tags, dependency parse and named entities.',\n",
       " 'link': '/usr/local/lib/python3.6/dist-packages/spacy/data/en',\n",
       " 'source': '/usr/local/lib/python3.6/dist-packages/en_core_web_sm'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model meta data\n",
    "\n",
    "spacy.info('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload the language model\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a Pandas Series of spaCy nlp variables\n",
    "\n",
    "doc_df = review_df['text'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The pizza was okay. Not the best I've had. I prefer Biaggio's on Flamingo / Fort Apache. The chef there can make a MUCH better NY style pizza. The pizzeria @ Cosmo was over priced for the quality and lack of personality in the food. Biaggio's is a much better pick if youre going for italian - family owned, home made recipes, people that actually CARE if you like their food. You dont get that at a pizzeria in a casino. I dont care what you say..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET DT\n",
      "pizza NOUN NN\n",
      "was VERB VBD\n",
      "okay ADJ JJ\n",
      ". PUNCT .\n",
      "Not ADV RB\n",
      "the DET DT\n",
      "best ADJ JJS\n",
      "I PRON PRP\n",
      "'ve VERB VB\n",
      "had VERB VBN\n",
      ". PUNCT .\n",
      "I PRON PRP\n",
      "prefer VERB VBP\n",
      "Biaggio PROPN NNP\n",
      "'s PART POS\n",
      "on ADP IN\n",
      "Flamingo PROPN NNP\n",
      "/ SYM SYM\n",
      "Fort PROPN NNP\n",
      "Apache PROPN NNP\n",
      ". PUNCT .\n",
      "The DET DT\n",
      "chef NOUN NN\n",
      "there ADV EX\n",
      "can VERB MD\n",
      "make VERB VB\n",
      "a DET DT\n",
      "MUCH ADV RB\n",
      "better ADJ JJR\n",
      "NY PROPN NNP\n",
      "style NOUN NN\n",
      "pizza NOUN NN\n",
      ". PUNCT .\n",
      "The DET DT\n",
      "pizzeria NOUN NN\n",
      "@ ADP IN\n",
      "Cosmo PROPN NNP\n",
      "was VERB VBD\n",
      "over ADV RB\n",
      "priced VERB VBN\n",
      "for ADP IN\n",
      "the DET DT\n",
      "quality NOUN NN\n",
      "and CCONJ CC\n",
      "lack NOUN NN\n",
      "of ADP IN\n",
      "personality NOUN NN\n",
      "in ADP IN\n",
      "the DET DT\n",
      "food NOUN NN\n",
      ". PUNCT .\n",
      "Biaggio PROPN NNP\n",
      "'s PART POS\n",
      "is VERB VBZ\n",
      "a DET DT\n",
      "much ADV RB\n",
      "better ADJ JJR\n",
      "pick NOUN NN\n",
      "if ADP IN\n",
      "you PRON PRP\n",
      "re VERB VBZ\n",
      "going VERB VBG\n",
      "for ADP IN\n",
      "italian ADJ JJ\n",
      "- PUNCT HYPH\n",
      "family NOUN NN\n",
      "owned VERB VBN\n",
      ", PUNCT ,\n",
      "home NOUN NN\n",
      "made VERB VBD\n",
      "recipes NOUN NNS\n",
      ", PUNCT ,\n",
      "people NOUN NNS\n",
      "that ADJ WDT\n",
      "actually ADV RB\n",
      "CARE VERB VBP\n",
      "if ADP IN\n",
      "you PRON PRP\n",
      "like VERB VBP\n",
      "their ADJ PRP$\n",
      "food NOUN NN\n",
      ". PUNCT .\n",
      "You PRON PRP\n",
      "do VERB VBP\n",
      "nt ADV RB\n",
      "get VERB VB\n",
      "that DET DT\n",
      "at ADP IN\n",
      "a DET DT\n",
      "pizzeria NOUN NN\n",
      "in ADP IN\n",
      "a DET DT\n",
      "casino NOUN NN\n",
      ". PUNCT .\n",
      "I PRON PRP\n",
      "do VERB VBP\n",
      "nt ADV RB\n",
      "care VERB VB\n",
      "what NOUN WP\n",
      "you PRON PRP\n",
      "say VERB VBP\n",
      "... PUNCT .\n"
     ]
    }
   ],
   "source": [
    "# spacy gives you both fine grained (.pos_) + coarse grained (.tag_) parts of speech    \n",
    "\n",
    "for doc in doc_df[0]:\n",
    "    print(doc.text, doc.pos_, doc.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The pizza, I, I, Biaggio, Flamingo / Fort Apache, The chef, a MUCH better NY style pizza, The pizzeria, Cosmo, the quality, lack, personality, the food, Biaggio, a much better pick, you, recipes, people, you, their food, You, a pizzeria, a casino, I, what, you]\n"
     ]
    }
   ],
   "source": [
    "# spaCy also does some basic noun chunking for us\n",
    "\n",
    "print([chunk for chunk in doc_df[0].noun_chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TextBlob\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TextBlob\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The default tagger in TextBlob uses the PatternTagger, the same as [pattern](https://www.clips.uantwerpen.be/pattern), which is fine for our example. To use the NLTK tagger, we can specify the pos_tagger when we call TextBlob. More [here](http://textblob.readthedocs.io/en/dev/advanced_usage.html#advanced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_df = review_df['text'].apply(TextBlob)\n",
    "type(blob_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.TextBlob"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(blob_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('pizza', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('okay', 'RB'),\n",
       " ('Not', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('I', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('had', 'VBN'),\n",
       " ('I', 'PRP'),\n",
       " ('prefer', 'VBP'),\n",
       " ('Biaggio', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('on', 'IN'),\n",
       " ('Flamingo', 'NNP'),\n",
       " ('/', 'NNP'),\n",
       " ('Fort', 'NNP'),\n",
       " ('Apache', 'NNP'),\n",
       " ('The', 'DT'),\n",
       " ('chef', 'NN'),\n",
       " ('there', 'EX'),\n",
       " ('can', 'MD'),\n",
       " ('make', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('MUCH', 'NNP'),\n",
       " ('better', 'JJR'),\n",
       " ('NY', 'NNP'),\n",
       " ('style', 'NN'),\n",
       " ('pizza', 'NN'),\n",
       " ('The', 'DT'),\n",
       " ('pizzeria', 'NN'),\n",
       " ('@', 'NNP'),\n",
       " ('Cosmo', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('over', 'RB'),\n",
       " ('priced', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('quality', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('lack', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('personality', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('food', 'NN'),\n",
       " ('Biaggio', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('much', 'RB'),\n",
       " ('better', 'RBR'),\n",
       " ('pick', 'NN'),\n",
       " ('if', 'IN'),\n",
       " ('youre', 'NN'),\n",
       " ('going', 'VBG'),\n",
       " ('for', 'IN'),\n",
       " ('italian', 'JJ'),\n",
       " ('family', 'NN'),\n",
       " ('owned', 'VBD'),\n",
       " ('home', 'NN'),\n",
       " ('made', 'VBD'),\n",
       " ('recipes', 'NNS'),\n",
       " ('people', 'NNS'),\n",
       " ('that', 'IN'),\n",
       " ('actually', 'RB'),\n",
       " ('CARE', 'VB'),\n",
       " ('if', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('like', 'VBP'),\n",
       " ('their', 'PRP$'),\n",
       " ('food', 'NN'),\n",
       " ('You', 'PRP'),\n",
       " ('dont', 'VBP'),\n",
       " ('get', 'VB'),\n",
       " ('that', 'DT'),\n",
       " ('at', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('pizzeria', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('casino', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('dont', 'VBP'),\n",
       " ('care', 'VB'),\n",
       " ('what', 'WP'),\n",
       " ('you', 'PRP'),\n",
       " ('say', 'VBP')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_df[0].tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biaggio', 'flamingo', '/ fort', 'apache', 'much', 'ny', 'style pizza', 'pizzeria @', 'cosmo', 'biaggio', 'care', 'dont care']\n"
     ]
    }
   ],
   "source": [
    "# blobs in TextBlob also have noun phrase extraction\n",
    "\n",
    "print([np for np in blob_df[0].noun_phrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
